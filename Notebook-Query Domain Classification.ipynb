{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F5F5F5; padding: 20px; font-family: 'Arial';\">\n",
    "<h1 style=\"font-size: 24px; color: #333333;\">Query Domain Classification</h1>\n",
    "\n",
    "<h4 style=\"font-size: 18px; color: #666666;\">2003-02, Consulting and Professional Communications, Assignment 1</h4>\n",
    "\n",
    "<p style=\"font-size: 16px; color: #333333;\">Shahabuddin Syed - 100895169</p>\n",
    "\n",
    "<hr style=\"border: none; border-top: 1px solid #CCCCCC; margin: 20px 0;\">\n",
    "\n",
    "<h3 style=\"font-size: 20px; color: #333333;\">Problem Statement:</h3>\n",
    "\n",
    "<p style=\"font-size: 16px; color: #333333;\">\n",
    "Build a system to categorize queries based on their domain using Natural Language Processing.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size: 16px; color: #333333;\">\n",
    "DSForum is a community-based portal where users can post queries related to data science topics such as machine learning, statistical analysis, data visualization, etc. The company aims to optimize the response time of queries by answering them promptly. However, the community can also provide answers through discussion forums. The queries can belong to various domains, including Techniques, Tools, Careers, etc.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size: 16px; color: #333333;\">\n",
    "Currently, users manually tag their queries when posting, selecting one of these categories: Techniques, Tools, Career, Hackathons, Resources, Misc, or Other. The query is then forwarded to the relevant team. However, this manual process is prone to errors and affects the query response time.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size: 16px; color: #333333;\">\n",
    "Can we design and develop a model that accurately classifies queries based on their domain? This will help improve the platform's response time by accurately identifying the domain of each query and redirecting it to the appropriate team for timely resolution.\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost classifier for gradient boosting\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Evaluation metric for measuring accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Text preprocessing\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Encoding categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Tokenization utility for text preprocessing\n",
    "import tiktoken\n",
    "\n",
    "# Utility function to obtain text embeddings\n",
    "from openai.embeddings_utils import get_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training data from 'train.csv' file\n",
    "train = pd.read_csv('train.csv').dropna(subset = ['Title'])\n",
    "\n",
    "# Read the test data from 'test.csv' file\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Read the sample submission file for reference\n",
    "sample = pd.read_csv('sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F9F9F9; padding: 20px;\">\n",
    "<h3 style=\"font-size: 20px; color: #333333;\">Text Preprocessing</h3>\n",
    "<p style=\"font-size: 16px; color: #666666;\">\n",
    "This function performs basic text preprocessing on a pandas Series of texts. The following steps are applied:\n",
    "</p>\n",
    "<ol style=\"font-size: 16px; color: #333333;\">\n",
    "    <li>Convert text to lowercase</li>\n",
    "    <li>Remove punctuation</li>\n",
    "    <li>Remove numbers</li>\n",
    "    <li>Tokenize text into words</li>\n",
    "    <li>Remove stopwords</li>\n",
    "    <li>Lemmatize words</li>\n",
    "    <li>Join preprocessed words back into sentences</li>\n",
    "</ol>\n",
    "<p style=\"font-size: 16px; color: #666666;\">\n",
    "The function takes a pandas Series containing the texts to be preprocessed and returns a new Series with the preprocessed texts.\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text_series):\n",
    "    \"\"\"\n",
    "    Function to perform basic text preprocessing on a pandas Series of texts.\n",
    "    \n",
    "    Parameters:\n",
    "    - text_series (pandas Series): Series containing the texts to be preprocessed.\n",
    "    \n",
    "    Returns:\n",
    "    - pandas Series: Series containing the preprocessed texts.\n",
    "    \"\"\"\n",
    "    # Convert text to lowercase\n",
    "    text_series = text_series.str.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text_series = text_series.str.replace('[{}]'.format(string.punctuation), '')\n",
    "    \n",
    "    # Remove numbers\n",
    "    text_series = text_series.str.replace('\\d+', '')\n",
    "    \n",
    "    # Tokenize text into words\n",
    "    text_series = text_series.apply(word_tokenize)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text_series = text_series.apply(lambda x: [word for word in x if word not in stop_words])\n",
    "    \n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text_series = text_series.apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "    \n",
    "    # Join the preprocessed words back into sentences\n",
    "    text_series = text_series.apply(lambda x: ' '.join(x))\n",
    "    \n",
    "    return text_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Title\"] = preprocess_text(train[\"Title\"])\n",
    "test[\"Title\"] = preprocess_text(test[\"Title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F9F9F9; padding: 20px;\">\n",
    "<h3 style=\"font-size: 20px; color: #333333;\">Text Embedding</h3>\n",
    "<p style=\"font-size: 16px; color: #666666;\">\n",
    "This function obtains embeddings for a pandas Series of texts. The following steps are performed:\n",
    "</p>\n",
    "<ol style=\"font-size: 16px; color: #333333;\">\n",
    "    <li>Specify the embedding model parameters</li>\n",
    "    <li>Obtain embeddings for each text using the get_embedding() function</li>\n",
    "</ol>\n",
    "<p style=\"font-size: 16px; color: #666666;\">\n",
    "The function takes a pandas Series containing the texts for which embeddings are to be obtained and returns a new Series with lists of embeddings corresponding to each text.\n",
    "</p>\n",
    "<div style=\"background-color: #D6ECFF; padding: 10px;\">\n",
    "    <p style=\"font-size: 16px; color: #333333;\">\n",
    "    <b>Note:</b> The embedding model parameters used in this function are as follows:\n",
    "    </p>\n",
    "    <ul style=\"font-size: 16px; color: #333333;\">\n",
    "        <li>Embedding Model: text-embedding-ada-002</li>\n",
    "        <li>Encoding: cl100k_base</li>\n",
    "        <li>Maximum Tokens: 8000</li>\n",
    "    </ul>\n",
    "</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embeddings(text_series):\n",
    "    \"\"\"\n",
    "    Function to obtain embeddings for a pandas Series of texts.\n",
    "    \n",
    "    Parameters:\n",
    "    - text_series (pandas Series): Series containing the texts for which embeddings are to be obtained.\n",
    "    \n",
    "    Returns:\n",
    "    - pandas Series: Series containing lists of embeddings corresponding to each text.\n",
    "    \"\"\"\n",
    "    # Embedding model parameters\n",
    "    embedding_model = \"text-embedding-ada-002\"\n",
    "    embedding_encoding = \"cl100k_base\"  # Encoding for text-embedding-ada-002\n",
    "    max_tokens = 8000  # Maximum tokens for text-embedding-ada-002 is 8191\n",
    "    \n",
    "    # Obtain embeddings for each text using the get_embedding() function\n",
    "    embeddings = text_series.apply(lambda x: get_embedding(x, engine=embedding_model))\n",
    "    \n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Convert \"Title\" column in the train DataFrame to embeddings\n",
    "train[\"embedding\"] = get_text_embeddings(train[\"Title\"])\n",
    "\n",
    "# Convert \"Title\" column in the test DataFrame to embeddings\n",
    "test[\"embedding\"] = get_text_embeddings(test[\"Title\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train DataFrame with embeddings\n",
    "train.to_pickle('train_embeddings.pkl')\n",
    "\n",
    "# Save test DataFrame with embeddings\n",
    "test.to_pickle('test_embeddings.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train DataFrame with embeddings\n",
    "train = pd.read_pickle('train_embeddings.pkl')\n",
    "\n",
    "# Load test DataFrame with embeddings\n",
    "test = pd.read_pickle('test_embeddings.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F9F9F9; padding: 20px;\">\n",
    "<h3 style=\"font-size: 20px; color: #333333;\">Model Building</h3>\n",
    "<p style=\"font-size: 16px; color: #666666;\">\n",
    "    This code performs the following steps to build a machine learning model for query domain classification:\n",
    "</p>\n",
    "<ol style=\"font-size: 16px; color: #333333;\">\n",
    "    <li>Extract embeddings from the 'embedding' column in the train DataFrame</li>\n",
    "    <li>Perform label encoding on the target variable ('Domain')</li>\n",
    "    <li>Split the dataset into training and validation sets</li>\n",
    "    <li>Define the XGBoost classifier with the specified parameters</li>\n",
    "    <li>Train the model using the training data and target variable</li>\n",
    "    <li>Make predictions on the validation set</li>\n",
    "    <li>Evaluate the model by calculating the accuracy score</li>\n",
    "</ol>\n",
    "<div style=\"background-color: #D6ECFF; padding: 10px;\">\n",
    "    <p style=\"font-size: 16px; color: #333333;\">\n",
    "        <b>Note:</b> The XGBoost classifier is configured as follows:\n",
    "    </p>\n",
    "    <ul style=\"font-size: 16px; color: #333333;\">\n",
    "        <li>Objective: multi:softmax</li>\n",
    "        <li>Number of estimators: 500</li>\n",
    "        <li>Maximum depth: 9</li>\n",
    "        <li>Number of parallel threads: -1 (using all available cores)</li>\n",
    "        <li>Learning rate: 0.02</li>\n",
    "        <li>Evaluation metric: mean absolute error (mae)</li>\n",
    "    </ul>\n",
    "</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6883963494132985\n"
     ]
    }
   ],
   "source": [
    "X = train[['embedding']].copy()\n",
    "X = X.embedding.apply(np.array)\n",
    "\n",
    "# Extract the target variable from the 'Domain' column and perform label encoding\n",
    "y = train['Domain'].copy()\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(list(X.values), y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the XGBoost classifier\n",
    "model = XGBClassifier(objective='multi:softmax', n_estimators=500, max_depth=9, n_jobs=-1, learning_rate=0.02, eval_metric='mae')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F9F9F9; padding: 20px;\">\n",
    "<h3 style=\"font-size: 20px; color: #333333;\">Testing the Model on Unseen Data</h3>\n",
    "<p style=\"font-size: 16px; color: #666666;\">\n",
    "    This code snippet performs the following steps to test the trained model on an unseen dataset:\n",
    "</p>\n",
    "<ol style=\"font-size: 16px; color: #333333;\">\n",
    "    <li>Prepare the test data by extracting embeddings from the 'embedding' column</li>\n",
    "    <li>Make predictions on the test data using the trained model</li>\n",
    "    <li>Convert the predicted labels back to their original domain categories</li>\n",
    "    <li>Assign the converted domain labels to the 'Domain' column in the sample DataFrame</li>\n",
    "</ol>\n",
    "<div style=\"background-color: #D6ECFF; padding: 10px;\">\n",
    "    <p style=\"font-size: 16px; color: #333333;\">\n",
    "        <b>Note:</b> The test data is assumed to have an 'embedding' column containing the embeddings for the text data. The trained model (`model`) and label encoder (`label_encoder`) are used in this process.\n",
    "    </p>\n",
    "</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test data\n",
    "test_x = test['embedding'].apply(np.array)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_preds = model.predict(list(test_x.values))\n",
    "\n",
    "# Convert the predicted labels back to their original domain categories\n",
    "sample['Domain'] = label_encoder.inverse_transform(test_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F9F9F9; padding: 20px;\">\n",
    "<h3 style=\"font-size: 20px; color: #333333;\">Predicting Domain for a Random Query</h3>\n",
    "<p style=\"font-size: 16px; color: #666666;\">\n",
    "    The following code demonstrates how to predict the domain for a random query using the trained model:\n",
    "</p>\n",
    "<p style=\"background-color: #D6ECFF; padding: 10px; font-size: 16px; color: #333333;\">\n",
    "    - Select a random query from the test dataset<br>\n",
    "    - Convert the query to an embedding<br>\n",
    "    - Reshape the embedding to match the input format expected by the model<br>\n",
    "    - Predict the domain for the random query using the model<br>\n",
    "    - Print the predicted domain\n",
    "</p>\n",
    "<p style=\"font-size: 16px; color: #666666;\">\n",
    "    This code selects a random query from the test dataset and converts it to an embedding. The embedding is then reshaped to match the input format expected by the model. Finally, the model predicts the domain for the random query, and the predicted domain is printed.\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Query: Help needed for sequence problem\n",
      "Predicted Domain: Techniques\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Random query\n",
    "random_query = random.choice(test['Title'])\n",
    "\n",
    "# Convert the query to embedding\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "random_query_embedding = get_embedding(random_query, engine=embedding_model)\n",
    "\n",
    "# Reshape the embedding to match the input format expected by the model\n",
    "random_query_embedding = np.array(random_query_embedding).reshape(1, -1)\n",
    "\n",
    "# Predict the domain for the random query\n",
    "predicted_domain = label_encoder.inverse_transform(model.predict(random_query_embedding))[0]\n",
    "\n",
    "# Print the predicted domain\n",
    "print(\"Random Query:\", random_query)\n",
    "print(\"Predicted Domain:\", predicted_domain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
